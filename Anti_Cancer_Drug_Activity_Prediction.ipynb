{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anti-Cancer Drug Activity Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vsxoMjV8jMPn",
        "YrTzZuGsjq0P",
        "Q81ZSVvXhMSB",
        "IBA7VX6xhMSV",
        "t_TggR4AhMSa",
        "ZReqwjj2Kkjl",
        "MR8hAIU9LMat",
        "YuxvsHDZwEAh",
        "3nV06VQMJjdT",
        "Ka-p6mJPJDga",
        "FJe1eiOOLXmG",
        "eASbS5s1QwAK",
        "2m8IPAB1wZAd",
        "YqtrUyrhRKt7",
        "Xq-gX-L8RcVz",
        "A9juJqkkVWI2",
        "Eg_5KuzzVcEZ",
        "vFSga8h1wse3",
        "FiDOZaDDVcEc",
        "RlXzOswhVcEg",
        "4IXmzRV8Xi9e",
        "adXgzA50Xi9f",
        "-7ojWP5Gw08u",
        "m26_DpZQXi9j",
        "SFEGcLTNXi9q",
        "1HiZqdoHYvj4",
        "lYhl5ue9Yvj6",
        "oUR240xAw83y",
        "Cc45PxcXYvj9",
        "6WMuTu-GYvj_",
        "aFvb6qK065Xp",
        "5i6mQwABZf9J",
        "HaUDsB_4Zf9K",
        "W4qhgL6QxGe-",
        "6QQMjtZzZf9L",
        "1QdUTEbZZf9N",
        "IdxF4TOKa6WY",
        "oMpGhSnwa6WZ",
        "AWiq6Ei-xP6u",
        "Em2pqeWxa6Wc",
        "YD-PyevTa6We",
        "EoMtjEyS5L7C",
        "R7vVAyKw5L7C",
        "snxwaG385L7E",
        "Qb7iN2Wr5L7F",
        "-QjL1LIw5L7G",
        "fBPxbkSOKIVk",
        "i3bPJr1dKDUK",
        "D2LUjuJHKDUO",
        "97QQYduCKDUP",
        "uco1TirRKDUR",
        "ASmB9LtlLKDR",
        "RI819obPLKDS",
        "GvQ0Il0wLKDU",
        "sBJjb2JuLKDW",
        "dxOBwnORLKDX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9f6db865d784058bba7924d21176394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77e8610e2651450c8f44658d67328f91",
              "IPY_MODEL_7bf0fa1403134cb8864392ddd4711f27",
              "IPY_MODEL_782240f44f4440d1af8d783fb4d24b67"
            ],
            "layout": "IPY_MODEL_fc36017f92584d0895e72af5a9b29e03"
          }
        },
        "77e8610e2651450c8f44658d67328f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e9d5f323c904f3ca1be0a76bfb29fea",
            "placeholder": "​",
            "style": "IPY_MODEL_421fc9921de94c3c94229837e0fe9676",
            "value": "100%"
          }
        },
        "7bf0fa1403134cb8864392ddd4711f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe19b7a3b8e449abb2d6e445c9d38a52",
            "max": 25024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e1ba21e380e477195fc482d70bc49ec",
            "value": 25024
          }
        },
        "782240f44f4440d1af8d783fb4d24b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40dffaea69a34fab8e66141d4ff09665",
            "placeholder": "​",
            "style": "IPY_MODEL_a774652535dc4cfe86cffe1780a12a1d",
            "value": " 25024/25024 [00:02&lt;00:00, 10663.09it/s]"
          }
        },
        "fc36017f92584d0895e72af5a9b29e03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e9d5f323c904f3ca1be0a76bfb29fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421fc9921de94c3c94229837e0fe9676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe19b7a3b8e449abb2d6e445c9d38a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1ba21e380e477195fc482d70bc49ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40dffaea69a34fab8e66141d4ff09665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a774652535dc4cfe86cffe1780a12a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01b92879f01445148b2eee2de6bd9535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91157be453be4ab1ae9c2accd8de37a0",
              "IPY_MODEL_9b2f4404e37d4d508c8033b6c42a25ff",
              "IPY_MODEL_3cf2fb611c324875b4a8ca59ddafd8eb"
            ],
            "layout": "IPY_MODEL_2cf9dc033d35443986d7d29e422b3fc3"
          }
        },
        "91157be453be4ab1ae9c2accd8de37a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62d12d972ac941c9be05544ab22e1911",
            "placeholder": "​",
            "style": "IPY_MODEL_1b8f14691e0c4310af170a225aeabbc5",
            "value": "100%"
          }
        },
        "9b2f4404e37d4d508c8033b6c42a25ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c43f4d185069453ba9c990092f04c2db",
            "max": 12326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a1f7488559a44e5994dfebeb0fc4768",
            "value": 12326
          }
        },
        "3cf2fb611c324875b4a8ca59ddafd8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40d005d5bb844180ab856ab7ffd1a782",
            "placeholder": "​",
            "style": "IPY_MODEL_b638df25a74a4e31acd643c49937d19b",
            "value": " 12326/12326 [00:01&lt;00:00, 10863.84it/s]"
          }
        },
        "2cf9dc033d35443986d7d29e422b3fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d12d972ac941c9be05544ab22e1911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b8f14691e0c4310af170a225aeabbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c43f4d185069453ba9c990092f04c2db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a1f7488559a44e5994dfebeb0fc4768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40d005d5bb844180ab856ab7ffd1a782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b638df25a74a4e31acd643c49937d19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Problem definition And questions Sol** "
      ],
      "metadata": {
        "id": "vsxoMjV8jMPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "😊 Problem Definition: \n",
        "  * It is a binary classification problem based on the graph data. \n",
        "  * The task is to predict the anticancer activity of a chemical compound using the chemical structure of the compound. \n",
        "  *The chemical compound can be positive or negative against lung cancer cell and thus labelled as either 0 or 1."
      ],
      "metadata": {
        "id": "90iAZfljZMVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "😊 Define the data input and output:-\n",
        "* The data is in the form of graph which represents the chemical structure of the compound. \n",
        "* Each sample of data contains information about the atoms and the connections between atoms of the molecule. \n",
        "* So in this problem the features are the atoms and connections.\n",
        "* The input file is structure data file (SDF). It contains information about the chemical composition of a molecule. SDF file store information about position of individual atom in the chemical compound and also tells about the connections."
      ],
      "metadata": {
        "id": "lCgZFc6aa1kZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "😊 What is the experimental protocol used and how was it carried out?\n",
        "* The first step is to read the sdf file to get the information about the atoms and their connectivity in the compound. The atoms are described as nodes and connections are described as edges. The read_sdf method is used to read sdf file and the chemical composition of the compound.\n",
        "* The nodes are given as characters (like [O,N,...]). Thus it is treated as sequence of text data and best way to describe the text data sequence to tokenize the data and then adding the embeddig layer.\n",
        "* Graph convolutional network is used to calculate the probability of the output class. Different methods differ in implementing message passing methods. "
      ],
      "metadata": {
        "id": "RHfoXltvfWrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✔️ **Answer the questions :**\n",
        "---\n",
        "---\n",
        "🌈**Based on the provided template, describe the format of the input file (sdf file).**\n",
        "\n",
        "* The input file is structure data file (SDF). It contains information about the chemical composition of a molecule. SDF file store information about position of individual atom in the chemical compound and also tells about the connections. Different molecules are delimited by```$$$$```expression.\n",
        "---\n",
        "* Each sample/molecule starts with header which tells about the name/title of the compound. Other sections includes information about Atom count, version number, connections etc. Atom block tells about the elements of the compound. Bond block block tells about the bonding structure of the compound. These both blocks are used in this assignment to get information about the compound and saving them in form of edges and nodes. Each node is the atom given in the chemical molecule.\n",
        "---\n",
        "---\n",
        "🌈**What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?**\n",
        "\n",
        "The input tensors in this network are:\n",
        "\n",
        "* data: The data contains the nodes of the chemical compound in the tokenized form. Nodes for each compound are extracted, then they are tokenized using the tokenizer and finally padding is done using pad_sequence method. The shape for each batch is [batch_size*max_len_nodes], where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done.\n",
        "---\n",
        "* edge: edge is the input tensor which carries information about connections between atoms. The shape of edge is [sum_of_all_edges,2]. The sum_of_all_edges represents the sum(no. of edges of each sample) of the batch_size. For example in a batch of 3 samples, the number of edges in sample 1: 21, sample 2: 20 and sample 3: 40. So the size of edge tensor would be [81,2].\n",
        "---\n",
        "* node2graph: It is the input tensor which is used for segmented mean and contains information about segmented ids. The shape for each batch is [batch_size*max_len_nodes], where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done.\n",
        "---\n",
        "---\n",
        "🌈**For each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?**\n",
        "\n",
        "* gnn_out: The gnn_out is of shape [batch_size_node_dimension,hidden layers], where batch_size_node_dimension is the dimension of the input data (node) vector (dimension of tokenized vector for the complete batch). It represents the aggregation output of the model for each hidden layer.\n",
        "---\n",
        "*  avg: Average takes the segmented mean of the gnn_out based on the segmented ids. For each sample in the batch_size, the output of gnn_out is [tokenized_vector_dimension, hidden_layers]. Each sample has one segment id. Thus the segment_mean takes the mean of all the output data in the gnn_out output and represents one sample with one number for each hidden layer. The final output of the avg tensor is of shape [batch_size, hidden_layer]. It is a way of collecting information for each sample and representing it in the form of mean data.\n",
        "---\n",
        "---\n",
        "🌈**What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?**\n",
        "\n",
        "* segment_mean takes the mean of the data which have same segmented ids.\n",
        "---\n",
        "* reduce_mean: computes the mean of elements across dimensions of a tensor given the arguments.\n",
        " Use TensorFlow reduce_mean operation to calculate the mean of tensor elements along various dimensions of the tensor.\n",
        "\n",
        "---\n",
        "* pred: The final output (pred) tells about the probability of a chemical compound to be active for the cancer cell or not. The shape of pred is [batch_size,1]. Thus for each sample, the final output is a number which represents the probability associated with each chemical compound about its activity.\n",
        "---\n",
        "---\n",
        "🌈**What is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?**\n",
        "\n",
        "* The default template implements the default setting of the number of layers in the gcn network. \n",
        "* The default layer are 4 as given in the documentaion. \n",
        "* The default message passing method is rgcn (Graph convolution layers). \n",
        "* Using multiple gcn helps in incorporating all the graph complexity properly and thus creates a better model."
      ],
      "metadata": {
        "id": "YrTzZuGsjq0P"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q81ZSVvXhMSB"
      },
      "source": [
        "# **Read SDF format data (structured-data format)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm_v7m8ahMSN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def read_sdf(file): \n",
        "#opening the file in read mode >>> 'r'            \n",
        "    with open(file, 'r') as rf:     \n",
        "#reading the contents of the file\n",
        "        content = rf.read()        \n",
        "#splitting the read file by delimiter $$$$  in the file thus splitting each molecule in an array        \n",
        "    samples = content.split('$$$$')\n",
        "#method to read each molecule configuration\n",
        "#s  represents one molecule\n",
        "    def parse_sample(s):\n",
        "#splitting the text data to lines\n",
        "        lines = s.splitlines()\n",
        "#empty array for links to save the values of links \n",
        "        links = []\n",
        "#empty array to save the nodes \n",
        "        nodes = []\n",
        "        label = 0\n",
        "#for loop over each line\n",
        "        for l in lines:\n",
        "            if l.strip() == '1.0':\n",
        "                label = 1\n",
        "            if l.strip() == '-1.0':\n",
        "                label = 0\n",
        "#for Atom block \n",
        "            if l.startswith('    '):\n",
        "#splitting line\n",
        "                feature = l.split()\n",
        "#node feature (atom) as O,C , \n",
        "                node = feature[3]\n",
        "#appending nodes\n",
        "                nodes.append(node)\n",
        "#bond block tells about connections between atoms\n",
        "            elif l.startswith(' '):\n",
        "#splitting line\n",
        "                lnk = l.split()\n",
        "# edge: (from, to,) (1-based index)\n",
        "                if int(lnk[0]) - 1 < len(nodes):\n",
        "#appending links\n",
        "                    links.append((\n",
        "#first atom\n",
        "                        int(lnk[0])-1, \n",
        "# zero-based index #second atom\n",
        "                        int(lnk[1])-1, # zero-based index\n",
        "# int(lnk[2]) ignore edge weight\n",
        "                    ))\n",
        "#returning nodes, links and label                    \n",
        "        return nodes, np.array(links), label\n",
        "#parse_sample for each molecule    \n",
        "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read raw train data\n",
        "!unzip /content/train_test.zip\n",
        "#load  train.sdf file\n",
        "training_set = read_sdf('train.sdf')\n",
        "#load test_x.sdf file\n",
        "testing_set  = read_sdf('test_x.sdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "b9f6db865d784058bba7924d21176394",
            "77e8610e2651450c8f44658d67328f91",
            "7bf0fa1403134cb8864392ddd4711f27",
            "782240f44f4440d1af8d783fb4d24b67",
            "fc36017f92584d0895e72af5a9b29e03",
            "8e9d5f323c904f3ca1be0a76bfb29fea",
            "421fc9921de94c3c94229837e0fe9676",
            "fe19b7a3b8e449abb2d6e445c9d38a52",
            "3e1ba21e380e477195fc482d70bc49ec",
            "40dffaea69a34fab8e66141d4ff09665",
            "a774652535dc4cfe86cffe1780a12a1d",
            "01b92879f01445148b2eee2de6bd9535",
            "91157be453be4ab1ae9c2accd8de37a0",
            "9b2f4404e37d4d508c8033b6c42a25ff",
            "3cf2fb611c324875b4a8ca59ddafd8eb",
            "2cf9dc033d35443986d7d29e422b3fc3",
            "62d12d972ac941c9be05544ab22e1911",
            "1b8f14691e0c4310af170a225aeabbc5",
            "c43f4d185069453ba9c990092f04c2db",
            "4a1f7488559a44e5994dfebeb0fc4768",
            "40d005d5bb844180ab856ab7ffd1a782",
            "b638df25a74a4e31acd643c49937d19b"
          ]
        },
        "id": "PemubsfMyhv7",
        "outputId": "5f56923d-0eea-4d54-a22d-99bc96eddfd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/train_test.zip\n",
            "replace test_x.sdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9f6db865d784058bba7924d21176394"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12326 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01b92879f01445148b2eee2de6bd9535"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrynV47phMSQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#splitting the train data into training set and validation set by 85 to 15 \n",
        "training_set, validation_set = train_test_split(training_set, test_size=0.15,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1s1ibivhMSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ade995-a889-46a2-c4a9-9899e1f3dbf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['O', 'O', 'O', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0, 16],\n",
            "       [ 1, 23],\n",
            "       [ 1, 28],\n",
            "       [ 2, 23],\n",
            "       [ 3,  7],\n",
            "       [ 3,  8],\n",
            "       [ 3, 10],\n",
            "       [ 3, 11],\n",
            "       [ 4,  5],\n",
            "       [ 4,  6],\n",
            "       [ 4,  7],\n",
            "       [ 5,  8],\n",
            "       [ 5, 15],\n",
            "       [ 6,  9],\n",
            "       [ 6, 16],\n",
            "       [ 9, 14],\n",
            "       [ 9, 21],\n",
            "       [10, 13],\n",
            "       [11, 12],\n",
            "       [12, 13],\n",
            "       [12, 17],\n",
            "       [13, 18],\n",
            "       [14, 15],\n",
            "       [14, 22],\n",
            "       [16, 23],\n",
            "       [17, 19],\n",
            "       [18, 20],\n",
            "       [19, 20],\n",
            "       [19, 25],\n",
            "       [20, 26],\n",
            "       [21, 24],\n",
            "       [22, 24],\n",
            "       [25, 27],\n",
            "       [26, 27]]), 0)\n"
          ]
        }
      ],
      "source": [
        "#print index 1 in the training set\n",
        "print(training_set[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBA7VX6xhMSV"
      },
      "source": [
        "# **Visualizing/Inspecting a Sample**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training set contains data for each sample(molecule). Each sample array contains three elements. First element has information about the atoms in text format, second element has information about the connections and third element tells about the label for each molecule."
      ],
      "metadata": {
        "id": "OeT6NfXHKybz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK1fWnZ0hMSW"
      },
      "outputs": [],
      "source": [
        "#importing libraries for displaying network of molecule\n",
        "!pip install --quiet networkx\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "colors = cm.rainbow(np.linspace(0, 1, 50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm9dG-_qhMSX"
      },
      "outputs": [],
      "source": [
        "#method to visualize the compound graph\n",
        "#atoms are given as nodes\n",
        "#the connections are defined as edges\n",
        "def visualize(sample):\n",
        "#initiating an instance of Graph\n",
        "    G=nx.Graph() \n",
        "#atoms as nodes\n",
        "    nodes = sample[0] \n",
        "#connections as edges\n",
        "    edges = sample[1] \n",
        "#empty dictionary for labels for the nodes\n",
        "    labeldict={} \n",
        "#empty array for each node color\n",
        "    node_color=[] \n",
        "#for each node in the sample\n",
        "    for i,n in enumerate(nodes): \n",
        "#adding node to the graph each node as (0,1,2,3..)\n",
        "        G.add_node(i)   \n",
        "#dictionary building with [key,value] as [0:'C']\n",
        "        labeldict[i]=n  \n",
        "#print(i)\n",
        "#print(n)\n",
        "#color coding\n",
        "        node_color.append(colors[hash(n)%len(colors)]) \n",
        "\n",
        "# a list of nodes:\n",
        "#for each edge\n",
        "    for e in edges:\n",
        "#adding egde to the graph from one connection to other connection\n",
        "        G.add_edge(e[0], e[1]) \n",
        "#drawing the graph with labels for nodes as atoms and connections as edges    \n",
        "    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
        "    plt.show()\n",
        "#returns graph\n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu04nA2FhMSZ",
        "outputId": "d348fb8c-c76c-404b-e2b3-bbd574e9967f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7fc88abc8490>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#displaying one sample\n",
        "plt.clf()\n",
        "visualize(training_set[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_TggR4AhMSa"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxLlarighMSb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_vocab = 500\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "all_nodes = [s[0] for s in training_set]\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mizZeMIIhMSb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "random.seed(10)\n",
        "\n",
        "#method to prepare single batch set\n",
        "#samples represents the batch of data\n",
        "def prepare_single_batch(samples):\n",
        " #nodes characters array\n",
        "    sample_nodes = [s[0] for s in samples]  \n",
        "#tokenizing the sample nodes                   \n",
        "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)   \n",
        "#pad_sequences for each sample node with post padding\n",
        "    sample_nodes = pad_sequences(sample_nodes, padding='post')  \n",
        "#maximum length of nodes \n",
        "    max_nodes_len = np.shape(sample_nodes)[1]                   \n",
        "#defining edges\n",
        "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)] \n",
        "    edges = [e for e in edges if len(e) > 0]\n",
        "#array definition for segmented_ids\n",
        "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]  \n",
        "#reshaping as 1 vector\n",
        "    all_nodes = np.reshape(sample_nodes, -1)  \n",
        "#concatenating all the edges as size [total_edges ,2]\n",
        "    all_edges = np.concatenate(edges)         \n",
        "\n",
        "    node_to_graph = np.reshape(node_to_graph, -1)\n",
        "#returns a dictionary of features(data,edges,node2grah) and label\n",
        "    return {\n",
        "        'data': all_nodes,\n",
        "        'edges': all_edges,\n",
        "        'node2grah': node_to_graph,\n",
        "    }, np.array([s[2] for s in samples]) \n",
        "\n",
        "#generating batch with given btch_size\n",
        "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
        " #infinity loop\n",
        "    while True:                \n",
        "#data in the array\n",
        "        dataset = list(dataset) \n",
        "# if shuffle is True\n",
        "        if shuffle:             \n",
        "#randomly shuffling\n",
        "            random.shuffle(dataset) \n",
        "#length of dataset\n",
        "        l = len(dataset)  \n",
        "#loop for  creating batches from given dataset\n",
        "        for ndx in range(0, l, batch_size):  \n",
        "#creating batch samples with given batch_size\n",
        "            batch_samples = dataset[ndx:min(ndx + batch_size, l)] \n",
        "#returning a generator with prepared batches\n",
        "            yield prepare_single_batch(batch_samples)  \n",
        "#breaking loop if repeat is false \n",
        "        if not repeat:  \n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ahKQi_8hMSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f758b54-24b0-48f8-e73f-f4c59b0826b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n",
            "[2 2 2 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 4 4 2 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 7 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 4 2 2 2 2 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1]\n",
            "edges\n",
            "[[  0   3]\n",
            " [  1   4]\n",
            " [  2   5]\n",
            " [  3   7]\n",
            " [  4  11]\n",
            " [  5  13]\n",
            " [  6   7]\n",
            " [  6  12]\n",
            " [  6  14]\n",
            " [  6  15]\n",
            " [  7   8]\n",
            " [  8  11]\n",
            " [  8  16]\n",
            " [  9  11]\n",
            " [  9  12]\n",
            " [  9  13]\n",
            " [ 10  13]\n",
            " [ 10  14]\n",
            " [ 10  16]\n",
            " [ 15  17]\n",
            " [ 15  18]\n",
            " [ 17  19]\n",
            " [ 18  20]\n",
            " [ 19  21]\n",
            " [ 20  21]\n",
            " [ 39  47]\n",
            " [ 39  51]\n",
            " [ 40  50]\n",
            " [ 40  52]\n",
            " [ 41  48]\n",
            " [ 42  44]\n",
            " [ 42  48]\n",
            " [ 42  50]\n",
            " [ 43  47]\n",
            " [ 43  50]\n",
            " [ 44  52]\n",
            " [ 45  52]\n",
            " [ 45  57]\n",
            " [ 46  47]\n",
            " [ 46  48]\n",
            " [ 46  49]\n",
            " [ 49  51]\n",
            " [ 49  53]\n",
            " [ 51  54]\n",
            " [ 53  55]\n",
            " [ 54  56]\n",
            " [ 55  56]\n",
            " [ 57  58]\n",
            " [ 57  59]\n",
            " [ 58  60]\n",
            " [ 59  61]\n",
            " [ 60  62]\n",
            " [ 60  63]\n",
            " [ 61  62]\n",
            " [ 78  90]\n",
            " [ 79  81]\n",
            " [ 79  85]\n",
            " [ 80  85]\n",
            " [ 81  82]\n",
            " [ 81  83]\n",
            " [ 82  86]\n",
            " [ 82  87]\n",
            " [ 83  84]\n",
            " [ 84  88]\n",
            " [ 84  90]\n",
            " [ 85  89]\n",
            " [ 86  89]\n",
            " [ 87  88]\n",
            " [117 119]\n",
            " [117 120]\n",
            " [117 125]\n",
            " [117 132]\n",
            " [118 129]\n",
            " [121 140]\n",
            " [121 154]\n",
            " [122 152]\n",
            " [122 155]\n",
            " [123 127]\n",
            " [123 128]\n",
            " [123 131]\n",
            " [124 127]\n",
            " [124 129]\n",
            " [124 130]\n",
            " [125 127]\n",
            " [126 128]\n",
            " [126 137]\n",
            " [128 129]\n",
            " [130 133]\n",
            " [130 134]\n",
            " [131 135]\n",
            " [131 136]\n",
            " [132 143]\n",
            " [132 144]\n",
            " [133 138]\n",
            " [134 139]\n",
            " [135 141]\n",
            " [136 142]\n",
            " [137 145]\n",
            " [137 146]\n",
            " [138 140]\n",
            " [139 140]\n",
            " [141 147]\n",
            " [142 147]\n",
            " [143 150]\n",
            " [144 151]\n",
            " [145 148]\n",
            " [146 149]\n",
            " [148 152]\n",
            " [149 152]\n",
            " [150 153]\n",
            " [151 153]]\n",
            "node2grah\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3]\n",
            "label [0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(training_set, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)\n",
        "        print(v)\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8MqrfhVhMSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85d6c52-54bf-4975-a381-7b5e364fd208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 54 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 58.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 134 kB 70.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 346 kB 76.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 61.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 67.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 73.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 209 kB/s \n",
            "\u001b[?25h  Building wheel for tf2-gnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet tf2_gnn\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#for deep Graph Neural Network\n",
        "from tf2_gnn.layers.gnn import GNN, GNNInput"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 1**"
      ],
      "metadata": {
        "id": "ZReqwjj2Kkjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i didn't change in the template so the accurracy between 70 and 78 % so  i will change in the hyperparameaters in the next trials and dcheck the performance "
      ],
      "metadata": {
        "id": "nQblYnnZhui6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "MR8hAIU9LMat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1WyfDCkhMSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a78cb58-8818-4a8b-f7c4-44b02ed5abac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100)          50000       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 40)           35440       ['embedding[0][0]',              \n",
            "                                                                  'input_2[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 40)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            41          ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 85,481\n",
            "Trainable params: 85,481\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#importing tensorflow and other libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data) \n",
        "data = keras.Input(batch_shape=(None,))             \n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data         \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)  \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector \n",
        "embeded = Embedding(tokenizer.num_words, 100)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))    \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "#sets the size of the output of all message passing layers.\n",
        "params[\"hidden_dim\"] = 40  \n",
        "\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]   \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    ) #shape: [batch_size,64]  \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        " #output shape: [batch_size,1]\n",
        "pred = Dense(1, activation='sigmoid')(avg)  \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "YuxvsHDZwEAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4PiB_rphMSf"
      },
      "outputs": [],
      "source": [
        "#compile the model by usnig adam as optimizer and \n",
        "#using binarycrossentropy for calculate the loss and check the acc by AUC \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "3nV06VQMJjdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0TX4ya6hMSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36de47fd-bdb5-42b4-a2bc-522f2261d4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/GatherV2_1_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_1_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape:0\", shape=(None, 40), dtype=float32), dense_shape=Tensor(\"gradients/rgcn/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2659/2659 [==============================] - 45s 14ms/step - loss: 0.2071 - auc: 0.5551 - val_loss: 0.2082 - val_auc: 0.6457\n",
            "Epoch 2/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1853 - auc: 0.6605 - val_loss: 0.1963 - val_auc: 0.6740\n",
            "Epoch 3/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1828 - auc: 0.6784 - val_loss: 0.1936 - val_auc: 0.7071\n",
            "Epoch 4/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1795 - auc: 0.6981 - val_loss: 0.1863 - val_auc: 0.7279\n",
            "Epoch 5/26\n",
            "2659/2659 [==============================] - 29s 11ms/step - loss: 0.1775 - auc: 0.7117 - val_loss: 0.1856 - val_auc: 0.7386\n",
            "Epoch 6/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1739 - auc: 0.7370 - val_loss: 0.1854 - val_auc: 0.7394\n",
            "Epoch 7/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1732 - auc: 0.7381 - val_loss: 0.1870 - val_auc: 0.7645\n",
            "Epoch 8/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1716 - auc: 0.7463 - val_loss: 0.1758 - val_auc: 0.7735\n",
            "Epoch 9/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1705 - auc: 0.7539 - val_loss: 0.1808 - val_auc: 0.7786\n",
            "Epoch 10/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1689 - auc: 0.7614 - val_loss: 0.1749 - val_auc: 0.7766\n",
            "Epoch 11/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1691 - auc: 0.7623 - val_loss: 0.1856 - val_auc: 0.7788\n",
            "Epoch 12/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1668 - auc: 0.7712 - val_loss: 0.1731 - val_auc: 0.7953\n",
            "Epoch 13/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1655 - auc: 0.7756 - val_loss: 0.1779 - val_auc: 0.7897\n",
            "Epoch 14/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1650 - auc: 0.7807 - val_loss: 0.1740 - val_auc: 0.7953\n",
            "Epoch 15/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1652 - auc: 0.7811 - val_loss: 0.1736 - val_auc: 0.7951\n",
            "Epoch 16/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1668 - auc: 0.7714 - val_loss: 0.1777 - val_auc: 0.7794\n",
            "Epoch 17/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1655 - auc: 0.7789 - val_loss: 0.1718 - val_auc: 0.7972\n",
            "Epoch 18/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1664 - auc: 0.7741 - val_loss: 0.1746 - val_auc: 0.7857\n",
            "Epoch 19/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1630 - auc: 0.7887 - val_loss: 0.1843 - val_auc: 0.8005\n",
            "Epoch 20/26\n",
            "2659/2659 [==============================] - 42s 16ms/step - loss: 0.1625 - auc: 0.7946 - val_loss: 0.1889 - val_auc: 0.7903\n",
            "Epoch 21/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1634 - auc: 0.7840 - val_loss: 0.1695 - val_auc: 0.8199\n",
            "Epoch 22/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1634 - auc: 0.7859 - val_loss: 0.1733 - val_auc: 0.7943\n",
            "Epoch 23/26\n",
            "2659/2659 [==============================] - 31s 12ms/step - loss: 0.1627 - auc: 0.7906 - val_loss: 0.1724 - val_auc: 0.7960\n",
            "Epoch 24/26\n",
            "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1629 - auc: 0.7930 - val_loss: 0.1723 - val_auc: 0.8068\n",
            "Epoch 25/26\n",
            "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1619 - auc: 0.7959 - val_loss: 0.1737 - val_auc: 0.7981\n",
            "Epoch 26/26\n",
            "2659/2659 [==============================] - 31s 12ms/step - loss: 0.1614 - auc: 0.8008 - val_loss: 0.1666 - val_auc: 0.8174\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc79a332050>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import math\n",
        "batch_size = 8\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "#train our model \n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "#the number of epochs \n",
        "    epochs=26,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "Ka-p6mJPJDga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vT7AAYWhMSg"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD9TqoHchMSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4ad52f-6b1c-42cf-8c17-f0dc08193219"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XawJOc-AhMSh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission 4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 2**"
      ],
      "metadata": {
        "id": "FJe1eiOOLXmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i change the \"message_calculation_class\" = 'GGNN' Compute new graph states by neural message passing and gated units on the nodes. but by using unbalanced data so we check the accurracy it is not good so we can check another hyperparameaters "
      ],
      "metadata": {
        "id": "ICCVGl_jUVqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "eASbS5s1QwAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 75)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 32 \n",
        "params[\"message_calculation_class\"] = 'GGNN'\n",
        "#params[\"num_edge_MLP_hidden_layers\"] = 16\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='relu')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_2 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFQUACLQMMNP",
        "outputId": "b65997b2-70d3-4aed-ba0c-5db70b18f536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_2/Sigmoid:0', description=\"created by layer 'dense_2'\")\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 75)           37500       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_1 (GNN)                    (None, 32)           49568       ['embedding_1[0][0]',            \n",
            "                                                                  'input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]',                \n",
            "                                                                  'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n",
            " mbda)                                                            'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 8)            264         ['tf.math.segment_mean_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            9           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 87,341\n",
            "Trainable params: 87,341\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "2m8IPAB1wZAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile( loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "XNAWokxlMSwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "YqtrUyrhRKt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_2.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59AN7PyeMXnM",
        "outputId": "33e3db86-1334-42fd-e418-8eeed58f5be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333/333 [==============================] - 9s 18ms/step - loss: 0.2007 - auc: 0.5789 - val_loss: 0.1853 - val_auc: 0.5971\n",
            "Epoch 2/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1840 - auc: 0.6532 - val_loss: 0.2332 - val_auc: 0.7117\n",
            "Epoch 3/20\n",
            "333/333 [==============================] - 6s 17ms/step - loss: 0.1812 - auc: 0.6686 - val_loss: 0.1828 - val_auc: 0.6150\n",
            "Epoch 4/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1778 - auc: 0.6888 - val_loss: 0.1743 - val_auc: 0.7369\n",
            "Epoch 5/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1748 - auc: 0.7025 - val_loss: 0.1728 - val_auc: 0.7568\n",
            "Epoch 6/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1742 - auc: 0.7084 - val_loss: 0.1870 - val_auc: 0.7141\n",
            "Epoch 7/20\n",
            "333/333 [==============================] - 6s 17ms/step - loss: 0.1738 - auc: 0.7109 - val_loss: 0.2026 - val_auc: 0.6134\n",
            "Epoch 8/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1726 - auc: 0.7190 - val_loss: 0.2120 - val_auc: 0.6911\n",
            "Epoch 9/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1725 - auc: 0.7175 - val_loss: 0.1602 - val_auc: 0.7408\n",
            "Epoch 10/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1708 - auc: 0.7276 - val_loss: 0.1887 - val_auc: 0.6488\n",
            "Epoch 11/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1694 - auc: 0.7353 - val_loss: 0.2330 - val_auc: 0.7433\n",
            "Epoch 12/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1677 - auc: 0.7459 - val_loss: 0.2025 - val_auc: 0.6977\n",
            "Epoch 13/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1669 - auc: 0.7467 - val_loss: 0.2127 - val_auc: 0.7217\n",
            "Epoch 14/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1662 - auc: 0.7537 - val_loss: 0.1726 - val_auc: 0.7287\n",
            "Epoch 15/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1650 - auc: 0.7615 - val_loss: 0.1763 - val_auc: 0.7101\n",
            "Epoch 16/20\n",
            "333/333 [==============================] - 6s 17ms/step - loss: 0.1637 - auc: 0.7661 - val_loss: 0.1794 - val_auc: 0.7450\n",
            "Epoch 17/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1617 - auc: 0.7759 - val_loss: 0.1836 - val_auc: 0.7737\n",
            "Epoch 18/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1612 - auc: 0.7776 - val_loss: 0.2041 - val_auc: 0.7857\n",
            "Epoch 19/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1582 - auc: 0.7892 - val_loss: 0.1361 - val_auc: 0.7837\n",
            "Epoch 20/20\n",
            "333/333 [==============================] - 6s 17ms/step - loss: 0.1572 - auc: 0.7862 - val_loss: 0.1718 - val_auc: 0.7213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc81724a910>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "Xq-gX-L8RcVz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MG2aqNuRcV0"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_2 = model_2.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_2 = np.reshape(y_pred_2, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b000d7f5-021c-4369-c9c9-e8329d2b1db5",
        "id": "47To3O_eRcV1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(y_pred_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5KtT-8tRcV2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_2})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 3**"
      ],
      "metadata": {
        "id": "A9juJqkkVWI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i added hyperparameters\n",
        "num_edge_MLP_hidden_layers by 16  and use message_calculation_class\" = 'RGCN' and another change in the number of a vector space of 50 dimensions in which words will be embedded and in hidden_dim by 64 when i fit the model the accuracy between 68 and 75 so we can check another hyperparameters and check the accurracy "
      ],
      "metadata": {
        "id": "sldUmrBxXcKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "Eg_5KuzzVcEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 50)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 64\n",
        "#Relational Graph Convolutional Networks  \n",
        "params[\"message_calculation_class\"] = 'RGCN'\n",
        "params[\"num_edge_MLP_hidden_layers\"] = 16\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='relu')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_3 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbb6a7b-028f-4c2b-a780-948d2f409864",
        "id": "m5dlot-zVcEa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_14/StatefulPartitionedCall:0', description=\"created by layer 'gnn_14'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_4/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_4'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_8/Sigmoid:0', description=\"created by layer 'dense_8'\")\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_45 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_43 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_14 (TFOpLam  ()                  0           ['input_45[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_14 (Embedding)       (None, 50)           25000       ['input_43[0][0]']               \n",
            "                                                                                                  \n",
            " input_44 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_14 (TFOpL  ()                  0           ['tf.math.reduce_max_14[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_14 (GNN)                   (None, 64)           73472       ['embedding_14[0][0]',           \n",
            "                                                                  'input_44[0][0]',               \n",
            "                                                                  'input_45[0][0]',               \n",
            "                                                                  'tf.__operators__.add_14[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_4 (TFOpLa  (None, 64)          0           ['gnn_14[0][0]',                 \n",
            " mbda)                                                            'input_45[0][0]']               \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 8)            520         ['tf.math.segment_mean_4[0][0]'] \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            9           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 99,001\n",
            "Trainable params: 99,001\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "vFSga8h1wse3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile( loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "1dt93CyxVcEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "FiDOZaDDVcEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_3.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c9eb30-5741-4a9c-cd1e-ac8339372616",
        "id": "GU9rXNVRVcEd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1751 - auc: 0.7295 - val_loss: 0.2285 - val_auc: 0.7233\n",
            "Epoch 2/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1765 - auc: 0.7158 - val_loss: 0.2303 - val_auc: 0.6152\n",
            "Epoch 3/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1764 - auc: 0.7207 - val_loss: 0.1883 - val_auc: 0.6889\n",
            "Epoch 4/20\n",
            "665/665 [==============================] - 9s 13ms/step - loss: 0.1761 - auc: 0.7159 - val_loss: 0.1631 - val_auc: 0.7958\n",
            "Epoch 5/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1760 - auc: 0.7107 - val_loss: 0.2046 - val_auc: 0.8144\n",
            "Epoch 6/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1767 - auc: 0.7063 - val_loss: 0.1715 - val_auc: 0.6941\n",
            "Epoch 7/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1761 - auc: 0.7097 - val_loss: 0.1960 - val_auc: 0.6863\n",
            "Epoch 8/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1771 - auc: 0.7044 - val_loss: 0.1754 - val_auc: 0.6919\n",
            "Epoch 9/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1760 - auc: 0.7112 - val_loss: 0.2011 - val_auc: 0.7813\n",
            "Epoch 10/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1765 - auc: 0.7019 - val_loss: 0.1867 - val_auc: 0.7566\n",
            "Epoch 11/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1767 - auc: 0.7035 - val_loss: 0.1941 - val_auc: 0.7304\n",
            "Epoch 12/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1759 - auc: 0.7109 - val_loss: 0.1555 - val_auc: 0.7226\n",
            "Epoch 13/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1766 - auc: 0.7114 - val_loss: 0.1494 - val_auc: 0.6608\n",
            "Epoch 14/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1766 - auc: 0.7081 - val_loss: 0.2874 - val_auc: 0.6348\n",
            "Epoch 15/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1736 - auc: 0.7267 - val_loss: 0.1534 - val_auc: 0.8270\n",
            "Epoch 16/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1737 - auc: 0.7325 - val_loss: 0.1758 - val_auc: 0.7494\n",
            "Epoch 17/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1726 - auc: 0.7382 - val_loss: 0.1655 - val_auc: 0.6154\n",
            "Epoch 18/20\n",
            "665/665 [==============================] - 9s 13ms/step - loss: 0.1738 - auc: 0.7320 - val_loss: 0.1410 - val_auc: 0.7668\n",
            "Epoch 19/20\n",
            "665/665 [==============================] - 8s 13ms/step - loss: 0.1724 - auc: 0.7330 - val_loss: 0.1858 - val_auc: 0.6932\n",
            "Epoch 20/20\n",
            "665/665 [==============================] - 8s 12ms/step - loss: 0.1708 - auc: 0.7431 - val_loss: 0.2051 - val_auc: 0.6812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc774096d10>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "RlXzOswhVcEg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coMiTD_XVcEg"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_3 = model_3.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_3 = np.reshape(y_pred_3, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e679763c-03ba-43cc-d087-23f46b5f94e4",
        "id": "BTKUm-iPVcEh"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(y_pred_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxW8zpSKVcEi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_3})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_3.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 4**"
      ],
      "metadata": {
        "id": "4IXmzRV8Xi9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used \"message_calculation_class\"= \"RGAT\"  and hidden_dim by 32 and num_heads by 32 and after i check the accurracy  and validation accuracy, the accuracy still between 70 and 80 % so we can check by another hyperparameaters "
      ],
      "metadata": {
        "id": "JRr8_lN2dyq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "adXgzA50Xi9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 60)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#\"message_calculation_class\" configures the message passing style. \n",
        "# This chooses the tf2_gnn.layers.message_passing.* layer used in each step.\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 32 \n",
        "#use GGNN as a calculation class \n",
        "params[\"message_calculation_class\"]= \"RGAT\" \n",
        "params[\"num_heads\"]=32\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "# create model \n",
        "model_4 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model_4.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3abf7d-4821-4eac-bfe4-ddb383a9639d",
        "id": "O23OVMMmXi9g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_18/StatefulPartitionedCall:0', description=\"created by layer 'gnn_18'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_6/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_6'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_10/Sigmoid:0', description=\"created by layer 'dense_10'\")\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_55 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_49 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_18 (TFOpLam  ()                  0           ['input_55[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_18 (Embedding)       (None, 60)           30000       ['input_49[0][0]']               \n",
            "                                                                                                  \n",
            " input_54 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_18 (TFOpL  ()                  0           ['tf.math.reduce_max_18[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_18 (GNN)                   (None, 32)           24000       ['embedding_18[0][0]',           \n",
            "                                                                  'input_54[0][0]',               \n",
            "                                                                  'input_55[0][0]',               \n",
            "                                                                  'tf.__operators__.add_18[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_6 (TFOpLa  (None, 32)          0           ['gnn_18[0][0]',                 \n",
            " mbda)                                                            'input_55[0][0]']               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 1)            33          ['tf.math.segment_mean_6[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 54,033\n",
            "Trainable params: 54,033\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "-7ojWP5Gw08u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile( loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "sfDhC3CaXi9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "m26_DpZQXi9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 400\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model_4.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=40,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=400, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1974ab0b-7892-472c-82ec-b7d5f66c084d",
        "id": "PNtnb5RJXi9l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "54/54 [==============================] - 6s 103ms/step - loss: 0.1836 - auc: 0.6680 - val_loss: 0.2164 - val_auc: 0.6919\n",
            "Epoch 2/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1825 - auc: 0.6695 - val_loss: 0.1960 - val_auc: 0.6047\n",
            "Epoch 3/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1795 - auc: 0.6889 - val_loss: 0.1938 - val_auc: 0.7299\n",
            "Epoch 4/40\n",
            "54/54 [==============================] - 5s 100ms/step - loss: 0.1796 - auc: 0.6853 - val_loss: 0.3025 - val_auc: 0.6765\n",
            "Epoch 5/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1792 - auc: 0.6978 - val_loss: 0.2289 - val_auc: 0.6121\n",
            "Epoch 6/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1789 - auc: 0.6916 - val_loss: 0.2236 - val_auc: 0.6587\n",
            "Epoch 7/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1789 - auc: 0.6967 - val_loss: 0.1731 - val_auc: 0.7439\n",
            "Epoch 8/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1777 - auc: 0.6953 - val_loss: 0.1798 - val_auc: 0.7609\n",
            "Epoch 9/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1769 - auc: 0.7053 - val_loss: 0.1666 - val_auc: 0.7291\n",
            "Epoch 10/40\n",
            "54/54 [==============================] - 5s 102ms/step - loss: 0.1767 - auc: 0.7088 - val_loss: 0.1827 - val_auc: 0.7252\n",
            "Epoch 11/40\n",
            "54/54 [==============================] - 5s 102ms/step - loss: 0.1768 - auc: 0.7175 - val_loss: 0.2784 - val_auc: 0.6643\n",
            "Epoch 12/40\n",
            "54/54 [==============================] - 5s 102ms/step - loss: 0.1751 - auc: 0.7160 - val_loss: 0.2022 - val_auc: 0.7767\n",
            "Epoch 13/40\n",
            "54/54 [==============================] - 5s 102ms/step - loss: 0.1746 - auc: 0.7220 - val_loss: 0.1880 - val_auc: 0.7045\n",
            "Epoch 14/40\n",
            "54/54 [==============================] - 6s 103ms/step - loss: 0.1747 - auc: 0.7135 - val_loss: 0.2078 - val_auc: 0.7420\n",
            "Epoch 15/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1741 - auc: 0.7238 - val_loss: 0.2320 - val_auc: 0.6711\n",
            "Epoch 16/40\n",
            "54/54 [==============================] - 5s 102ms/step - loss: 0.1724 - auc: 0.7366 - val_loss: 0.1653 - val_auc: 0.6943\n",
            "Epoch 17/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1738 - auc: 0.7282 - val_loss: 0.1641 - val_auc: 0.7807\n",
            "Epoch 18/40\n",
            "54/54 [==============================] - 6s 102ms/step - loss: 0.1733 - auc: 0.7309 - val_loss: 0.2108 - val_auc: 0.7543\n",
            "Epoch 19/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1716 - auc: 0.7370 - val_loss: 0.1963 - val_auc: 0.7118\n",
            "Epoch 20/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1718 - auc: 0.7361 - val_loss: 0.2065 - val_auc: 0.7117\n",
            "Epoch 21/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1716 - auc: 0.7356 - val_loss: 0.2024 - val_auc: 0.7034\n",
            "Epoch 22/40\n",
            "54/54 [==============================] - 6s 102ms/step - loss: 0.1712 - auc: 0.7411 - val_loss: 0.2408 - val_auc: 0.7121\n",
            "Epoch 23/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1713 - auc: 0.7437 - val_loss: 0.2011 - val_auc: 0.6949\n",
            "Epoch 24/40\n",
            "54/54 [==============================] - 6s 102ms/step - loss: 0.1706 - auc: 0.7461 - val_loss: 0.1673 - val_auc: 0.7871\n",
            "Epoch 25/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1716 - auc: 0.7412 - val_loss: 0.1939 - val_auc: 0.7477\n",
            "Epoch 26/40\n",
            "54/54 [==============================] - 5s 100ms/step - loss: 0.1699 - auc: 0.7498 - val_loss: 0.2411 - val_auc: 0.6934\n",
            "Epoch 27/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1720 - auc: 0.7416 - val_loss: 0.2048 - val_auc: 0.7260\n",
            "Epoch 28/40\n",
            "54/54 [==============================] - 5s 102ms/step - loss: 0.1713 - auc: 0.7438 - val_loss: 0.1770 - val_auc: 0.7582\n",
            "Epoch 29/40\n",
            "54/54 [==============================] - 5s 100ms/step - loss: 0.1706 - auc: 0.7492 - val_loss: 0.1957 - val_auc: 0.7078\n",
            "Epoch 30/40\n",
            "54/54 [==============================] - 5s 100ms/step - loss: 0.1698 - auc: 0.7508 - val_loss: 0.2192 - val_auc: 0.7522\n",
            "Epoch 31/40\n",
            "54/54 [==============================] - 5s 100ms/step - loss: 0.1697 - auc: 0.7453 - val_loss: 0.1730 - val_auc: 0.7825\n",
            "Epoch 32/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1704 - auc: 0.7435 - val_loss: 0.2442 - val_auc: 0.7222\n",
            "Epoch 33/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1710 - auc: 0.7418 - val_loss: 0.1729 - val_auc: 0.7771\n",
            "Epoch 34/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1700 - auc: 0.7481 - val_loss: 0.2174 - val_auc: 0.7213\n",
            "Epoch 35/40\n",
            "54/54 [==============================] - 5s 102ms/step - loss: 0.1687 - auc: 0.7538 - val_loss: 0.2451 - val_auc: 0.7135\n",
            "Epoch 36/40\n",
            "54/54 [==============================] - 5s 102ms/step - loss: 0.1705 - auc: 0.7415 - val_loss: 0.2007 - val_auc: 0.7034\n",
            "Epoch 37/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1694 - auc: 0.7474 - val_loss: 0.2389 - val_auc: 0.7424\n",
            "Epoch 38/40\n",
            "54/54 [==============================] - 5s 101ms/step - loss: 0.1686 - auc: 0.7521 - val_loss: 0.2301 - val_auc: 0.7538\n",
            "Epoch 39/40\n",
            "54/54 [==============================] - 6s 112ms/step - loss: 0.1689 - auc: 0.7509 - val_loss: 0.1679 - val_auc: 0.7751\n",
            "Epoch 40/40\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.1668 - auc: 0.7620 - val_loss: 0.2878 - val_auc: 0.7260\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc74d933a10>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "SFEGcLTNXi9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIXIUjsKXi9r"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_4 = model_4.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_4 = np.reshape(y_pred_4, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDfQNv2xXi9s"
      },
      "outputs": [],
      "source": [
        "len(y_pred_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiH4es8KXi9u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_4})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 5**"
      ],
      "metadata": {
        "id": "1HiZqdoHYvj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i change in \"message_calculation_class\"] = 'RGIN' and change in another hyperparameaters after i check the accurracy it between 70 and 80 % so we can check by another hyperparameaters "
      ],
      "metadata": {
        "id": "hJGPcdfWZi36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "lYhl5ue9Yvj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 150)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 50\n",
        "#Relational Graph Isomorphism Networks \n",
        "params[\"message_calculation_class\"] = 'RGIN'\n",
        "params[\"num_edge_MLP_hidden_layers\"] = 32 ##\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='relu')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_5 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3754d957-a9ec-4a8d-f939-8ca53fd275fa",
        "id": "5-XyYgVQYvj7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_3/StatefulPartitionedCall:0', description=\"created by layer 'gnn_3'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_3/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_3'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_5/Sigmoid:0', description=\"created by layer 'dense_5'\")\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  ()                  0           ['input_12[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 75)           37500       ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  ()                  0           ['tf.math.reduce_max_3[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_3 (GNN)                    (None, 32)           49568       ['embedding_3[0][0]',            \n",
            "                                                                  'input_11[0][0]',               \n",
            "                                                                  'input_12[0][0]',               \n",
            "                                                                  'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TFOpLa  (None, 32)          0           ['gnn_3[0][0]',                  \n",
            " mbda)                                                            'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 8)            264         ['tf.math.segment_mean_3[0][0]'] \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            9           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 87,341\n",
            "Trainable params: 87,341\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "oUR240xAw83y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile( loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "yaPBjUy_Yvj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "Cc45PxcXYvj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_5.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec78db71-0c36-4e0b-89d7-c5736da61b40",
        "id": "jUysWoZCYvj-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333/333 [==============================] - 21s 48ms/step - loss: 0.2035 - auc: 0.5818 - val_loss: 0.1738 - val_auc: 0.6971\n",
            "Epoch 2/20\n",
            "333/333 [==============================] - 13s 39ms/step - loss: 0.1853 - auc: 0.6527 - val_loss: 0.2159 - val_auc: 0.6590\n",
            "Epoch 3/20\n",
            "333/333 [==============================] - 14s 42ms/step - loss: 0.1826 - auc: 0.6702 - val_loss: 0.1593 - val_auc: 0.7007\n",
            "Epoch 4/20\n",
            "333/333 [==============================] - 11s 35ms/step - loss: 0.1820 - auc: 0.6720 - val_loss: 0.1662 - val_auc: 0.7348\n",
            "Epoch 5/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1789 - auc: 0.6963 - val_loss: 0.1573 - val_auc: 0.6940\n",
            "Epoch 6/20\n",
            "333/333 [==============================] - 12s 35ms/step - loss: 0.1769 - auc: 0.7051 - val_loss: 0.2160 - val_auc: 0.7162\n",
            "Epoch 7/20\n",
            "333/333 [==============================] - 15s 47ms/step - loss: 0.1746 - auc: 0.7209 - val_loss: 0.2088 - val_auc: 0.7885\n",
            "Epoch 8/20\n",
            "333/333 [==============================] - 13s 39ms/step - loss: 0.1728 - auc: 0.7329 - val_loss: 0.1708 - val_auc: 0.7275\n",
            "Epoch 9/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1707 - auc: 0.7435 - val_loss: 0.1721 - val_auc: 0.7992\n",
            "Epoch 10/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1703 - auc: 0.7506 - val_loss: 0.1918 - val_auc: 0.6650\n",
            "Epoch 11/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1682 - auc: 0.7660 - val_loss: 0.1816 - val_auc: 0.7570\n",
            "Epoch 12/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1679 - auc: 0.7598 - val_loss: 0.1854 - val_auc: 0.7161\n",
            "Epoch 13/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1668 - auc: 0.7698 - val_loss: 0.1900 - val_auc: 0.6939\n",
            "Epoch 14/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1663 - auc: 0.7729 - val_loss: 0.1550 - val_auc: 0.8007\n",
            "Epoch 15/20\n",
            "333/333 [==============================] - 12s 35ms/step - loss: 0.1631 - auc: 0.7831 - val_loss: 0.1554 - val_auc: 0.8011\n",
            "Epoch 16/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1622 - auc: 0.7894 - val_loss: 0.1966 - val_auc: 0.7657\n",
            "Epoch 17/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1611 - auc: 0.7895 - val_loss: 0.1512 - val_auc: 0.8249\n",
            "Epoch 18/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1597 - auc: 0.7949 - val_loss: 0.1834 - val_auc: 0.7505\n",
            "Epoch 19/20\n",
            "333/333 [==============================] - 12s 35ms/step - loss: 0.1576 - auc: 0.8009 - val_loss: 0.1669 - val_auc: 0.7975\n",
            "Epoch 20/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1575 - auc: 0.8062 - val_loss: 0.1641 - val_auc: 0.7896\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6315cc4590>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "6WMuTu-GYvj_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67wprhPxYvkA"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_5 = model_5.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_5 = np.reshape(y_pred_5, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daeda023-f400-4c05-8fa2-f02f5877a8d2",
        "id": "l29-K92dYvkA"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "len(y_pred_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxxhESMCYvkB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_5})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_5.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Solve Unbalanced Data** "
      ],
      "metadata": {
        "id": "aFvb6qK065Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "#read the training data as a dataframe\n",
        "df = pd.DataFrame(training_set,columns=['Nodes','Edges','Labels']) \n",
        "df_majority = df[df['Labels']==0]  #data with majority class\n",
        "df_minority = df[df['Labels']==1]  #data with maniority class\n",
        "\n",
        "print('Shape of Unbalanced Data before Upsampling:')\n",
        "print(df_majority.shape)\n",
        "print(df_minority .shape)\n",
        "print('\\n')\n",
        "\n",
        "# Upsample minority class\n",
        "df_minority_upsampled = resample(df_minority,\n",
        "                                  # sample with replacement \n",
        "                                 replace=True, \n",
        "                                 # to match majority class                 \n",
        "                                 n_samples=len(df_majority),\n",
        "                                  # reproducible results     \n",
        "                                 random_state=42)               \n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "# Display new class counts\n",
        "print('New class counts after Upsampling:')\n",
        "df_upsampled['Labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54O_g_it7H9R",
        "outputId": "7682e814-b342-4907-d65f-9526f7a2bea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Unbalanced Data before Upsampling:\n",
            "(23806, 3)\n",
            "(1218, 3)\n",
            "\n",
            "\n",
            "New class counts after Upsampling:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    23806\n",
              "1    23806\n",
              "Name: Labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the dataframe of data to numpy array so we can deal with\n",
        "training_set= df_upsampled.to_numpy()"
      ],
      "metadata": {
        "id": "uXWIFQvm7Z4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 6 With Balanced Data**"
      ],
      "metadata": {
        "id": "5i6mQwABZf9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The GNN layer takes a GNNInput named tuple as input, which encapsulates:\n",
        "\n",
        "  1) Initial node features\n",
        "\n",
        "  2) Adjacency lists\n",
        "\n",
        "  3) Auxiliary information\n",
        "\n",
        "In this trial we will use   \"message_calculation_class\": \"gnn_edge_mlp\" which configures the message passing style\n",
        "\n",
        "the accuracy improved and became between 80 and 97 % \n"
      ],
      "metadata": {
        "id": "JL0Y9Rsmekmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "HaUDsB_4Zf9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model \n",
        "from tensorflow.keras.layers import Embedding, Dense \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "#identify the 4 GNNInput inputs(data, edge, node2graph, num_graph)\n",
        "data = keras.Input(batch_shape=(None,))                           #Input layer for nodes (tokenized text data)            \n",
        "embeded = Embedding(tokenizer.num_words, 100)(data)               #embedding layer over data with each token embedded as  size vector \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)         #Input layer for edge data         \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)     #Input layer for node2graph ids    \n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1                           #number of graphs (number of samples) \n",
        "\n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 64 \n",
        "#defining hidden dimension of the gnn layer(the output of all message passing layers)                   \n",
        "params[\"message_calculation_class\"] = 'gnn_edge_mlp'\n",
        "params[\"num_aggr_MLP_hidden_layers\"] = 4\n",
        "\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )                                     \n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid activation function\n",
        "pred = Dense(1, activation='sigmoid')(avg)    \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "# input : dictionary of data,edges and node2graph\n",
        "# output: prediction value from dense layer\n",
        "\n",
        "model_6 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#display model summary \n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54862583-f3e5-438a-aeac-560195847106",
        "id": "qUp9LjyiZf9K"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_23/StatefulPartitionedCall:0', description=\"created by layer 'gnn_23'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_8/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_8'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_12/Sigmoid:0', description=\"created by layer 'dense_12'\")\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_70 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_68 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_23 (TFOpLam  ()                  0           ['input_70[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_23 (Embedding)       (None, 100)          50000       ['input_68[0][0]']               \n",
            "                                                                                                  \n",
            " input_69 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_23 (TFOpL  ()                  0           ['tf.math.reduce_max_23[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_23 (GNN)                   (None, 64)           76672       ['embedding_23[0][0]',           \n",
            "                                                                  'input_69[0][0]',               \n",
            "                                                                  'input_70[0][0]',               \n",
            "                                                                  'tf.__operators__.add_23[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_8 (TFOpLa  (None, 64)          0           ['gnn_23[0][0]',                 \n",
            " mbda)                                                            'input_70[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 1)            65          ['tf.math.segment_mean_8[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 126,737\n",
            "Trainable params: 126,737\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "W4qhgL6QxGe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.compile(optimizer='adam', loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "jFgRqiMUZf9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "6QQMjtZzZf9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_6.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9438bd0-c3bb-42d1-8eeb-a230b6c5daee",
        "id": "pCGMHj3vZf9M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__edge_mlp_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__edge_mlp_2/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__edge_mlp_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__edge_mlp/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__edge_mlp/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__edge_mlp/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2976/2976 [==============================] - 34s 11ms/step - loss: 0.5995 - auc: 0.7417 - val_loss: 0.5528 - val_auc: 0.8042\n",
            "Epoch 2/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.5590 - auc: 0.7850 - val_loss: 0.5967 - val_auc: 0.8210\n",
            "Epoch 3/20\n",
            "2976/2976 [==============================] - 34s 11ms/step - loss: 0.5271 - auc: 0.8149 - val_loss: 0.5770 - val_auc: 0.8550\n",
            "Epoch 4/20\n",
            "2976/2976 [==============================] - 33s 11ms/step - loss: 0.5048 - auc: 0.8338 - val_loss: 0.4679 - val_auc: 0.8591\n",
            "Epoch 5/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.4755 - auc: 0.8548 - val_loss: 0.4227 - val_auc: 0.8866\n",
            "Epoch 6/20\n",
            "2976/2976 [==============================] - 33s 11ms/step - loss: 0.4494 - auc: 0.8717 - val_loss: 0.4294 - val_auc: 0.8909\n",
            "Epoch 7/20\n",
            "2976/2976 [==============================] - 33s 11ms/step - loss: 0.4228 - auc: 0.8874 - val_loss: 0.6321 - val_auc: 0.8943\n",
            "Epoch 8/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.4028 - auc: 0.8982 - val_loss: 0.4264 - val_auc: 0.9066\n",
            "Epoch 9/20\n",
            "2976/2976 [==============================] - 33s 11ms/step - loss: 0.3853 - auc: 0.9070 - val_loss: 0.4394 - val_auc: 0.9283\n",
            "Epoch 10/20\n",
            "2976/2976 [==============================] - 42s 14ms/step - loss: 0.3642 - auc: 0.9172 - val_loss: 0.3558 - val_auc: 0.9318\n",
            "Epoch 11/20\n",
            "2976/2976 [==============================] - 35s 12ms/step - loss: 0.3471 - auc: 0.9244 - val_loss: 0.3572 - val_auc: 0.9373\n",
            "Epoch 12/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.3333 - auc: 0.9305 - val_loss: 0.3755 - val_auc: 0.9382\n",
            "Epoch 13/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.3197 - auc: 0.9364 - val_loss: 0.3507 - val_auc: 0.9477\n",
            "Epoch 14/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.3040 - auc: 0.9418 - val_loss: 0.3233 - val_auc: 0.9522\n",
            "Epoch 15/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.2928 - auc: 0.9464 - val_loss: 0.4094 - val_auc: 0.9552\n",
            "Epoch 16/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.2853 - auc: 0.9485 - val_loss: 0.3550 - val_auc: 0.9573\n",
            "Epoch 17/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.2762 - auc: 0.9519 - val_loss: 0.2840 - val_auc: 0.9628\n",
            "Epoch 18/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.2702 - auc: 0.9540 - val_loss: 0.2980 - val_auc: 0.9641\n",
            "Epoch 19/20\n",
            "2976/2976 [==============================] - 39s 13ms/step - loss: 0.2590 - auc: 0.9573 - val_loss: 0.4333 - val_auc: 0.9650\n",
            "Epoch 20/20\n",
            "2976/2976 [==============================] - 32s 11ms/step - loss: 0.2532 - auc: 0.9591 - val_loss: 0.2804 - val_auc: 0.9659\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc899b54e10>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "1QdUTEbZZf9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDTjXF5VZf9N"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_6 = model_6.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_6 = np.reshape(y_pred_6, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daeda023-f400-4c05-8fa2-f02f5877a8d2",
        "id": "ahyovT8AZf9N"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "len(y_pred_6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AijQu8PPZf9O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_6})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_6.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 7 With Balanced Data**"
      ],
      "metadata": {
        "id": "IdxF4TOKa6WY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used \"message_calculation_class\"] ='GNN_FiLM'\n",
        "and \"film_parameter_MLP_hidden_layers\" by 1   the accuracy became between 90 and 98 % so this is the best model "
      ],
      "metadata": {
        "id": "PkY-xHaCfUSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "oMpGhSnwa6WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model \n",
        "from tensorflow.keras.layers import Embedding, Dense \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "#identify the 4 GNNInput inputs(data, edge, node2graph, num_graph)\n",
        "#Input layer for nodes (tokenized text data)\n",
        "data = keras.Input(batch_shape=(None,))\n",
        "#embedding layer over data with each token embedded as  size vector \n",
        "#the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "embeded = Embedding(tokenizer.num_words, 100)(data)              \n",
        "#Input layer for edge data \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)         \n",
        "#Input layer for node2graph ids         \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)        \n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1                           \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 64\n",
        "#defining hidden dimension of the gnn layer(the output of all message passing layers)\n",
        "params[\"film_parameter_MLP_hidden_layers\"] = 1\n",
        "params[\"message_calculation_class\"] ='GNN_FiLM'\n",
        "\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )                                     \n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid activation function\n",
        "pred = Dense(1, activation='sigmoid')(avg)    \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "\"\"\"\n",
        "input : dictionary of data,edges and node2graph\n",
        "output: prediction value from dense layer\n",
        "\"\"\"\n",
        "model_7 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#display model summary \n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5318a193-061f-4dbe-ba91-e17a11583ee5",
        "id": "vsJQ7_4Ra6Wa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_30/StatefulPartitionedCall:0', description=\"created by layer 'gnn_30'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_10/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_10'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_14/Sigmoid:0', description=\"created by layer 'dense_14'\")\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_91 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_89 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_30 (TFOpLam  ()                  0           ['input_91[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_30 (Embedding)       (None, 100)          50000       ['input_89[0][0]']               \n",
            "                                                                                                  \n",
            " input_90 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_30 (TFOpL  ()                  0           ['tf.math.reduce_max_30[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_30 (GNN)                   (None, 64)           174976      ['embedding_30[0][0]',           \n",
            "                                                                  'input_90[0][0]',               \n",
            "                                                                  'input_91[0][0]',               \n",
            "                                                                  'tf.__operators__.add_30[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_10 (TFOpL  (None, 64)          0           ['gnn_30[0][0]',                 \n",
            " ambda)                                                           'input_91[0][0]']               \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 1)            65          ['tf.math.segment_mean_10[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 225,041\n",
            "Trainable params: 225,041\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "AWiq6Ei-xP6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.compile(optimizer='adam',loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "ZraMVZu_a6Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "Em2pqeWxa6Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "batch_size = 32\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_7.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a3f13d2-5e9e-4827-f9f5-f5ac1064c748",
        "id": "yHuhQHU8a6Wd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_2:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm_2/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1488/1488 [==============================] - 23s 14ms/step - loss: 0.5885 - auc: 0.7519 - val_loss: 0.5474 - val_auc: 0.8361\n",
            "Epoch 2/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.5036 - auc: 0.8361 - val_loss: 0.5500 - val_auc: 0.8779\n",
            "Epoch 3/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.4372 - auc: 0.8808 - val_loss: 0.5655 - val_auc: 0.9208\n",
            "Epoch 4/20\n",
            "1488/1488 [==============================] - 22s 15ms/step - loss: 0.3838 - auc: 0.9092 - val_loss: 0.3800 - val_auc: 0.9312\n",
            "Epoch 5/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.3443 - auc: 0.9271 - val_loss: 0.3952 - val_auc: 0.9357\n",
            "Epoch 6/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.3168 - auc: 0.9383 - val_loss: 0.2619 - val_auc: 0.9475\n",
            "Epoch 7/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2940 - auc: 0.9466 - val_loss: 0.3109 - val_auc: 0.9507\n",
            "Epoch 8/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2754 - auc: 0.9531 - val_loss: 0.3945 - val_auc: 0.9640\n",
            "Epoch 9/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2567 - auc: 0.9588 - val_loss: 0.3114 - val_auc: 0.9696\n",
            "Epoch 10/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2352 - auc: 0.9651 - val_loss: 0.3469 - val_auc: 0.9646\n",
            "Epoch 11/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2306 - auc: 0.9660 - val_loss: 0.2643 - val_auc: 0.9723\n",
            "Epoch 12/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2131 - auc: 0.9706 - val_loss: 0.3490 - val_auc: 0.9691\n",
            "Epoch 13/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2069 - auc: 0.9718 - val_loss: 0.2736 - val_auc: 0.9818\n",
            "Epoch 14/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.1939 - auc: 0.9752 - val_loss: 0.2853 - val_auc: 0.9799\n",
            "Epoch 15/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.1917 - auc: 0.9759 - val_loss: 0.2257 - val_auc: 0.9767\n",
            "Epoch 16/20\n",
            "1488/1488 [==============================] - 29s 19ms/step - loss: 0.1886 - auc: 0.9761 - val_loss: 0.3791 - val_auc: 0.9784\n",
            "Epoch 17/20\n",
            "1488/1488 [==============================] - 26s 17ms/step - loss: 0.1832 - auc: 0.9775 - val_loss: 0.2223 - val_auc: 0.9813\n",
            "Epoch 18/20\n",
            "1488/1488 [==============================] - 20s 14ms/step - loss: 0.1815 - auc: 0.9783 - val_loss: 0.3050 - val_auc: 0.9768\n",
            "Epoch 19/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.1647 - auc: 0.9811 - val_loss: 0.1966 - val_auc: 0.9895\n",
            "Epoch 20/20\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.1618 - auc: 0.9817 - val_loss: 0.1958 - val_auc: 0.9791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc72a12ea50>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "YD-PyevTa6We"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjeZET1Fa6Wf"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_7 = model_7.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_7 = np.reshape(y_pred_7, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95e87f2-caf3-4deb-86ad-ab61e0e08bb2",
        "id": "cTT9AU69a6Wf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "len(y_pred_7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfdD5-6ya6Wg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_7})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_7.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 8 With Balanced Data**"
      ],
      "metadata": {
        "id": "EoMtjEyS5L7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used last \"message_calculation_class\"] ='GNN_FiLM' but different hyperparameaters and after i check the accurracy it began by 82 and increase until 95 and decrease again to 75 % "
      ],
      "metadata": {
        "id": "89UJ8fbUf7X5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "R7vVAyKw5L7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model \n",
        "from tensorflow.keras.layers import Embedding, Dense \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "\n",
        "#identify the 4 GNNInput inputs(data, edge, node2graph, num_graph)\n",
        "#Input layer for nodes (tokenized text data)\n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "#embedding layer over data with each token embedded as  size vector                                      \n",
        "embeded = Embedding(tokenizer.num_words, 100)(data)               \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)         \n",
        "#Input layer for node2graph ids        \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)         \n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1                           \n",
        "\n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer(the output of all message passing layers)\n",
        "params[\"hidden_dim\"] = 40\n",
        "params[\"film_parameter_MLP_hidden_layers\"] = 1\n",
        "params[\"message_calculation_class\"] ='GNN_FiLM'\n",
        "\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )                                     \n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid activation function\n",
        "pred = Dense(1, activation='sigmoid')(avg)    \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "# input : dictionary of data,edges and node2graph\n",
        "# output: prediction value from dense layer\n",
        "\n",
        "model_8 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#display model summary \n",
        "model_8.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8b51a5-5a33-40c3-e655-50fb9a1e465b",
        "id": "g_mzYT4u5L7D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_31/StatefulPartitionedCall:0', description=\"created by layer 'gnn_31'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_11/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_11'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_15/Sigmoid:0', description=\"created by layer 'dense_15'\")\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_94 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_92 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_31 (TFOpLam  ()                  0           ['input_94[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_31 (Embedding)       (None, 100)          50000       ['input_92[0][0]']               \n",
            "                                                                                                  \n",
            " input_93 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_31 (TFOpL  ()                  0           ['tf.math.reduce_max_31[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_31 (GNN)                   (None, 64)           174976      ['embedding_31[0][0]',           \n",
            "                                                                  'input_93[0][0]',               \n",
            "                                                                  'input_94[0][0]',               \n",
            "                                                                  'tf.__operators__.add_31[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_11 (TFOpL  (None, 64)          0           ['gnn_31[0][0]',                 \n",
            " ambda)                                                           'input_94[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 1)            65          ['tf.math.segment_mean_11[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 225,041\n",
            "Trainable params: 225,041\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "snxwaG385L7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC'])"
      ],
      "metadata": {
        "id": "Ac8tX-UL5L7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "Qb7iN2Wr5L7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "num_batchs            = math.ceil(len(training_set) / batch_size)   #no. of batches for training data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) #no. of batches for validation data\n",
        "\n",
        "model_8.fit(\n",
        "    gen_batch(training_set, batch_size=batch_size, repeat=True),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    validation_data=gen_batch(validation_set, batch_size=batch_size, repeat=True),\n",
        "    validation_steps=num_batchs_validation,\n",
        "     epochs=35,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94f4dac-3243-4ade-a7f5-7e252101f329",
        "id": "Pd5Rl4RF5L7F"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_2:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm_2/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1488/1488 [==============================] - 27s 17ms/step - loss: 0.5834 - auc: 0.7578 - val_loss: 0.5000 - val_auc: 0.8283\n",
            "Epoch 2/35\n",
            "1488/1488 [==============================] - 20s 13ms/step - loss: 0.5033 - auc: 0.8351 - val_loss: 0.5327 - val_auc: 0.8742\n",
            "Epoch 3/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.4516 - auc: 0.8716 - val_loss: 0.5248 - val_auc: 0.9126\n",
            "Epoch 4/35\n",
            "1488/1488 [==============================] - 31s 21ms/step - loss: 0.4051 - auc: 0.8985 - val_loss: 0.4522 - val_auc: 0.9221\n",
            "Epoch 5/35\n",
            "1488/1488 [==============================] - 32s 21ms/step - loss: 0.3758 - auc: 0.9134 - val_loss: 0.4478 - val_auc: 0.9331\n",
            "Epoch 6/35\n",
            "1488/1488 [==============================] - 28s 19ms/step - loss: 0.3628 - auc: 0.9198 - val_loss: 0.3199 - val_auc: 0.9329\n",
            "Epoch 7/35\n",
            "1488/1488 [==============================] - 24s 16ms/step - loss: 0.3580 - auc: 0.9219 - val_loss: 0.3148 - val_auc: 0.9372\n",
            "Epoch 8/35\n",
            "1488/1488 [==============================] - 20s 13ms/step - loss: 0.3361 - auc: 0.9319 - val_loss: 0.3559 - val_auc: 0.9590\n",
            "Epoch 9/35\n",
            "1488/1488 [==============================] - 22s 15ms/step - loss: 0.3249 - auc: 0.9363 - val_loss: 0.4189 - val_auc: 0.9429\n",
            "Epoch 10/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2969 - auc: 0.9465 - val_loss: 0.3360 - val_auc: 0.9605\n",
            "Epoch 11/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.3065 - auc: 0.9431 - val_loss: 0.3406 - val_auc: 0.9522\n",
            "Epoch 12/35\n",
            "1488/1488 [==============================] - 24s 16ms/step - loss: 0.3223 - auc: 0.9381 - val_loss: 0.2550 - val_auc: 0.9598\n",
            "Epoch 13/35\n",
            "1488/1488 [==============================] - 33s 22ms/step - loss: 0.2952 - auc: 0.9472 - val_loss: 0.3693 - val_auc: 0.9638\n",
            "Epoch 14/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2999 - auc: 0.9456 - val_loss: 0.3657 - val_auc: 0.9574\n",
            "Epoch 15/35\n",
            "1488/1488 [==============================] - 20s 13ms/step - loss: 0.2706 - auc: 0.9555 - val_loss: 0.3269 - val_auc: 0.9678\n",
            "Epoch 16/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2731 - auc: 0.9546 - val_loss: 0.2669 - val_auc: 0.9653\n",
            "Epoch 17/35\n",
            "1488/1488 [==============================] - 23s 15ms/step - loss: 0.2817 - auc: 0.9521 - val_loss: 0.5423 - val_auc: 0.9370\n",
            "Epoch 18/35\n",
            "1488/1488 [==============================] - 22s 15ms/step - loss: 0.3070 - auc: 0.9421 - val_loss: 0.3319 - val_auc: 0.9539\n",
            "Epoch 19/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2971 - auc: 0.9457 - val_loss: 0.3136 - val_auc: 0.9515\n",
            "Epoch 20/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2613 - auc: 0.9572 - val_loss: 0.2801 - val_auc: 0.9671\n",
            "Epoch 21/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2885 - auc: 0.9485 - val_loss: 0.3700 - val_auc: 0.9570\n",
            "Epoch 22/35\n",
            "1488/1488 [==============================] - 21s 14ms/step - loss: 0.2634 - auc: 0.9566 - val_loss: 0.3826 - val_auc: 0.9508\n",
            "Epoch 23/35\n",
            "1488/1488 [==============================] - 34s 23ms/step - loss: 0.2428 - auc: 0.9629 - val_loss: 0.3411 - val_auc: 0.9720\n",
            "Epoch 24/35\n",
            "1488/1488 [==============================] - 33s 22ms/step - loss: 0.2334 - auc: 0.9656 - val_loss: 0.2130 - val_auc: 0.9781\n",
            "Epoch 25/35\n",
            "1488/1488 [==============================] - 22s 15ms/step - loss: 0.2168 - auc: 0.9698 - val_loss: 0.3309 - val_auc: 0.9667\n",
            "Epoch 26/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.2157 - auc: 0.9698 - val_loss: 0.3174 - val_auc: 0.9758\n",
            "Epoch 27/35\n",
            "1488/1488 [==============================] - 20s 13ms/step - loss: 0.5234 - auc: 0.8187 - val_loss: 0.5567 - val_auc: 0.7569\n",
            "Epoch 28/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.5920 - auc: 0.7536 - val_loss: 0.7125 - val_auc: 0.7624\n",
            "Epoch 29/35\n",
            "1488/1488 [==============================] - 20s 13ms/step - loss: 0.5936 - auc: 0.7517 - val_loss: 0.6409 - val_auc: 0.7679\n",
            "Epoch 30/35\n",
            "1488/1488 [==============================] - 24s 16ms/step - loss: 0.5955 - auc: 0.7462 - val_loss: 0.7276 - val_auc: 0.7601\n",
            "Epoch 31/35\n",
            "1488/1488 [==============================] - 22s 15ms/step - loss: 0.5956 - auc: 0.7458 - val_loss: 0.6058 - val_auc: 0.7642\n",
            "Epoch 32/35\n",
            "1488/1488 [==============================] - 24s 16ms/step - loss: 0.5857 - auc: 0.7609 - val_loss: 0.6175 - val_auc: 0.7792\n",
            "Epoch 33/35\n",
            "1488/1488 [==============================] - 32s 21ms/step - loss: 0.5804 - auc: 0.7665 - val_loss: 0.6086 - val_auc: 0.7758\n",
            "Epoch 34/35\n",
            "1488/1488 [==============================] - 21s 14ms/step - loss: 0.5898 - auc: 0.7540 - val_loss: 0.7193 - val_auc: 0.7351\n",
            "Epoch 35/35\n",
            "1488/1488 [==============================] - 19s 13ms/step - loss: 0.5897 - auc: 0.7548 - val_loss: 0.7659 - val_auc: 0.7471\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc725c08350>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "-QjL1LIw5L7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6XYYEpe5L7G"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_8 = model_8.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_8 = np.reshape(y_pred_8, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3910cdd0-8c2f-49b7-d4c5-50b033915ea1",
        "id": "wyDSNHXA5L7H"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "len(y_pred_8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XYx9oDg5L7H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_8})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_8.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 9 With Balanced Data** "
      ],
      "metadata": {
        "id": "fBPxbkSOKIVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used as the second trial but after balance the data so the accurracy became between 80 and 95 % but not stables "
      ],
      "metadata": {
        "id": "jtPlQ0_kghh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "i3bPJr1dKDUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 75)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 32 \n",
        "params[\"message_calculation_class\"] = 'GGNN'\n",
        "#params[\"num_edge_MLP_hidden_layers\"] = 16\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='relu')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_9 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_9.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89653708-1173-4715-b89f-b03cc67650d2",
        "id": "IKSKgiCpKDUM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_32/StatefulPartitionedCall:0', description=\"created by layer 'gnn_32'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_12/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_12'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_17/Sigmoid:0', description=\"created by layer 'dense_17'\")\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_97 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_95 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_32 (TFOpLam  ()                  0           ['input_97[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_32 (Embedding)       (None, 75)           37500       ['input_95[0][0]']               \n",
            "                                                                                                  \n",
            " input_96 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_32 (TFOpL  ()                  0           ['tf.math.reduce_max_32[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_32 (GNN)                   (None, 32)           49568       ['embedding_32[0][0]',           \n",
            "                                                                  'input_96[0][0]',               \n",
            "                                                                  'input_97[0][0]',               \n",
            "                                                                  'tf.__operators__.add_32[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_12 (TFOpL  (None, 32)          0           ['gnn_32[0][0]',                 \n",
            " ambda)                                                           'input_97[0][0]']               \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 8)            264         ['tf.math.segment_mean_12[0][0]']\n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 1)            9           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 87,341\n",
            "Trainable params: 87,341\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "D2LUjuJHKDUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_9.compile(optimizer='adam',loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "XDP5dGy8KDUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "97QQYduCKDUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_9.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c088a60-4536-4ca4-d5f5-48bac5ed4a06",
        "id": "9MeARrFbKDUQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "744/744 [==============================] - 15s 16ms/step - loss: 0.6221 - auc: 0.7026 - val_loss: 0.7142 - val_auc: 0.7850\n",
            "Epoch 2/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.5840 - auc: 0.7515 - val_loss: 0.7190 - val_auc: 0.7463\n",
            "Epoch 3/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.5520 - auc: 0.7866 - val_loss: 0.6035 - val_auc: 0.8340\n",
            "Epoch 4/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.5163 - auc: 0.8233 - val_loss: 0.7111 - val_auc: 0.8289\n",
            "Epoch 5/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.4882 - auc: 0.8450 - val_loss: 0.4801 - val_auc: 0.7708\n",
            "Epoch 6/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.4669 - auc: 0.8600 - val_loss: 0.5073 - val_auc: 0.9070\n",
            "Epoch 7/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.4435 - auc: 0.8750 - val_loss: 0.6184 - val_auc: 0.8735\n",
            "Epoch 8/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.4258 - auc: 0.8856 - val_loss: 0.6269 - val_auc: 0.9451\n",
            "Epoch 9/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.4070 - auc: 0.8959 - val_loss: 0.4856 - val_auc: 0.9229\n",
            "Epoch 10/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.3928 - auc: 0.9035 - val_loss: 0.6310 - val_auc: 0.9190\n",
            "Epoch 11/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.3754 - auc: 0.9120 - val_loss: 0.6012 - val_auc: 0.9218\n",
            "Epoch 12/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.3624 - auc: 0.9179 - val_loss: 0.6551 - val_auc: 0.9172\n",
            "Epoch 13/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.3479 - auc: 0.9242 - val_loss: 0.4888 - val_auc: 0.9440\n",
            "Epoch 14/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.3312 - auc: 0.9312 - val_loss: 0.5835 - val_auc: 0.9499\n",
            "Epoch 15/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.3217 - auc: 0.9345 - val_loss: 0.5001 - val_auc: 0.9196\n",
            "Epoch 16/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.3091 - auc: 0.9396 - val_loss: 0.5217 - val_auc: 0.9515\n",
            "Epoch 17/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.2983 - auc: 0.9433 - val_loss: 0.5854 - val_auc: 0.9354\n",
            "Epoch 18/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.2891 - auc: 0.9465 - val_loss: 0.5108 - val_auc: 0.9568\n",
            "Epoch 19/20\n",
            "744/744 [==============================] - 11s 14ms/step - loss: 0.2798 - auc: 0.9497 - val_loss: 0.5001 - val_auc: 0.9544\n",
            "Epoch 20/20\n",
            "744/744 [==============================] - 11s 15ms/step - loss: 0.2754 - auc: 0.9510 - val_loss: 0.4708 - val_auc: 0.9275\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc723583710>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "uco1TirRKDUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bBt0vv1KDUS"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_9 = model_2.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_9 = np.reshape(y_pred_9, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891f5279-6279-43f2-e0bd-f841c73a1aee",
        "id": "GpERbG5oKDUT"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "len(y_pred_9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yB-2OiwKDUT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_9})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_9.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 10 With Balanced Data**"
      ],
      "metadata": {
        "id": "ASmB9LtlLKDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used \"message_calculation_class\"] = 'RGCN' as the same in the third trial with the balanced data so the accurracy became 80 and 95 and if i increase in the number of epochs the performance of the model will increase "
      ],
      "metadata": {
        "id": "CVxUPxkJhHgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "RI819obPLKDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 50)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 64\n",
        "#Relational Graph Convolutional Networks  \n",
        "params[\"message_calculation_class\"] = 'RGCN'\n",
        "# params[\"num_edge_MLP_hidden_layers\"] = 32\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='LeakyReLU')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_10 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_10.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1f7c2c-4937-470c-e19c-69b1b335f46b",
        "id": "4JT0pEOhLKDT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_39/StatefulPartitionedCall:0', description=\"created by layer 'gnn_39'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_19/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_19'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_28/Sigmoid:0', description=\"created by layer 'dense_28'\")\n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_118 (InputLayer)         [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_116 (InputLayer)         [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_39 (TFOpLam  ()                  0           ['input_118[0][0]']              \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_39 (Embedding)       (None, 50)           25000       ['input_116[0][0]']              \n",
            "                                                                                                  \n",
            " input_117 (InputLayer)         [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_39 (TFOpL  ()                  0           ['tf.math.reduce_max_39[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_39 (GNN)                   (None, 64)           73472       ['embedding_39[0][0]',           \n",
            "                                                                  'input_117[0][0]',              \n",
            "                                                                  'input_118[0][0]',              \n",
            "                                                                  'tf.__operators__.add_39[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_19 (TFOpL  (None, 64)          0           ['gnn_39[0][0]',                 \n",
            " ambda)                                                           'input_118[0][0]']              \n",
            "                                                                                                  \n",
            " dense_27 (Dense)               (None, 8)            520         ['tf.math.segment_mean_19[0][0]']\n",
            "                                                                                                  \n",
            " dense_28 (Dense)               (None, 1)            9           ['dense_27[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 99,001\n",
            "Trainable params: 99,001\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "GvQ0Il0wLKDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.compile(optimizer='adam', loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "wnoXZeLlLKDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "sBJjb2JuLKDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_10.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b22a63a-2a0d-4e75-8bf4-47fa0e67dd7b",
        "id": "ZvlTA8cjLKDW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/rgcn_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/rgcn/embedding_lookup_grad/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradients/rgcn/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1488/1488 [==============================] - 20s 12ms/step - loss: 0.6136 - auc: 0.7221 - val_loss: 0.7920 - val_auc: 0.7382\n",
            "Epoch 2/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.5791 - auc: 0.7635 - val_loss: 0.6940 - val_auc: 0.7828\n",
            "Epoch 3/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.5589 - auc: 0.7846 - val_loss: 0.5736 - val_auc: 0.8197\n",
            "Epoch 4/20\n",
            "1488/1488 [==============================] - 18s 12ms/step - loss: 0.5388 - auc: 0.8037 - val_loss: 0.7145 - val_auc: 0.8238\n",
            "Epoch 5/20\n",
            "1488/1488 [==============================] - 18s 12ms/step - loss: 0.5153 - auc: 0.8244 - val_loss: 0.6158 - val_auc: 0.8504\n",
            "Epoch 6/20\n",
            "1488/1488 [==============================] - 18s 12ms/step - loss: 0.4928 - auc: 0.8414 - val_loss: 0.5702 - val_auc: 0.8771\n",
            "Epoch 7/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.4733 - auc: 0.8560 - val_loss: 0.6385 - val_auc: 0.8837\n",
            "Epoch 8/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.4543 - auc: 0.8689 - val_loss: 0.5683 - val_auc: 0.8631\n",
            "Epoch 9/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.4334 - auc: 0.8814 - val_loss: 0.3984 - val_auc: 0.9363\n",
            "Epoch 10/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.4161 - auc: 0.8913 - val_loss: 0.5535 - val_auc: 0.8596\n",
            "Epoch 11/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.3971 - auc: 0.9014 - val_loss: 0.4631 - val_auc: 0.9116\n",
            "Epoch 12/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.3799 - auc: 0.9102 - val_loss: 0.4611 - val_auc: 0.9205\n",
            "Epoch 13/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.3635 - auc: 0.9178 - val_loss: 0.4904 - val_auc: 0.9421\n",
            "Epoch 14/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.3491 - auc: 0.9238 - val_loss: 0.4654 - val_auc: 0.9394\n",
            "Epoch 15/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.3406 - auc: 0.9275 - val_loss: 0.4839 - val_auc: 0.9441\n",
            "Epoch 16/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.3285 - auc: 0.9325 - val_loss: 0.3966 - val_auc: 0.9457\n",
            "Epoch 17/20\n",
            "1488/1488 [==============================] - 17s 11ms/step - loss: 0.3161 - auc: 0.9372 - val_loss: 0.4825 - val_auc: 0.9559\n",
            "Epoch 18/20\n",
            "1488/1488 [==============================] - 17s 12ms/step - loss: 0.3044 - auc: 0.9418 - val_loss: 0.3360 - val_auc: 0.9434\n",
            "Epoch 19/20\n",
            "1488/1488 [==============================] - 17s 11ms/step - loss: 0.2960 - auc: 0.9445 - val_loss: 0.3546 - val_auc: 0.9547\n",
            "Epoch 20/20\n",
            "1488/1488 [==============================] - 29s 20ms/step - loss: 0.2863 - auc: 0.9479 - val_loss: 0.3531 - val_auc: 0.9490\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc71992bcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "dxOBwnORLKDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoxKSoCZLKDX"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_10 = model_10.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_10 = np.reshape(y_pred_10, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a35c1e7-0a1f-44ca-c54b-a39753e4d2a8",
        "id": "NuyFY-nLLKDX"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "len(y_pred_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZdL9i5ZLKDY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_10})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_10.csv')"
      ]
    }
  ]
}